{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ultralytics\n",
    "#ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!yolo task=detect mode=train model=yolov8n.pt data=../all_datasets/camera-dataset/data.yaml epochs=30 imgsz=640 save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with static image\n",
    "from PIL import Image\n",
    "image = \"../localTesting/video0_6.jpg\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelC = YOLO(\"models/C/weights/C.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testResults = modelC(image, stream=True)\\n\\nfor r in testResults:\\n    boxes = r.boxes\\n    for box in boxes:\\n        conf = math.ceil(box.conf[0]*100) / 100\\n        className = box.cls[0]\\n        print(conf)\\n        print(className)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"testResults = modelC(image, stream=True)\n",
    "\n",
    "for r in testResults:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "        conf = math.ceil(box.conf[0]*100) / 100\n",
    "        className = box.cls[0]\n",
    "        print(conf)\n",
    "        print(className)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/dogukan/repos/safety_ai/object_detector_model_training/../localTesting/video0_6.jpg: 640x256 1 helmet, 1 vest, 48.4ms\n",
      "Speed: 2.7ms preprocess, 48.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 256)\n"
     ]
    }
   ],
   "source": [
    "# performing inference\n",
    "with torch.no_grad():\n",
    "    results = modelC(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of a 'result' object\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# boxes: bounding boxes of 'detected objects,' Each represented by the coordinates of its 'top-left corner,' 'width,' and 'height.'\n",
    "# keypoints: this is part of human pose estimation and not used in typical object detection tasks.\n",
    "# keys: list of keys that represent what kind of objects are available (we have just 'boxes' in this case)\n",
    "# masks: segmentation masks of detected objects, if any. (NONE)\n",
    "# names: dictionary mapping the class IDs with their names (labels).\n",
    "# orig_img: original image in numpy array format...\n",
    "# probs: The probabilities (model's confidence) of each detected object.\n",
    "# save_dir: the directory to which any saves files related to the current detection task would be written.\n",
    "# speed: contains the time taken for different steps of the detection process.\n",
    "\n",
    "# Structure of boxes,\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# xyxy   :box with xyxy format, (N, 4)\n",
    "# xywh   :box with xywh format, (N, 4)\n",
    "# xyxyn  :box with xyxy format but normalized, (N, 4)\n",
    "# xywhn  :box with xywh format but normalized, (N, 4)\n",
    "# conf   :confidence score, (N, 1)\n",
    "# cls    :cls, (N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8998, 0.7748])\n",
      "tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "        \n",
    "    classID = res.boxes.cls\n",
    "    prob = res.boxes.conf\n",
    "    print(prob)\n",
    "    print(classID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for name in modelC.names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.8997514843940735\n",
      "Class: helmet, Confidence: 0.8997514843940735\n",
      "1\n",
      "1.7747745513916016\n",
      "Class: vest, Confidence: 0.7747745513916016\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "classNames = [\"helmet\", \"vest\"]\n",
    "\n",
    "for res in results:\n",
    "    classIDs = res.boxes.cls\n",
    "    probabilities = res.boxes.conf\n",
    "\n",
    "    for classID, prob in zip(classIDs, probabilities):\n",
    "        classID = int(classID.item())\n",
    "        print(classID)\n",
    "        prob = prob.item()\n",
    "        if(prob>0.5): print(prob)\n",
    "        print(f\"Class: {classNames[int(classID)]}, Confidence: {prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
